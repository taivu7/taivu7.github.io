---
title: "Post Training in Large Language Models - Part 1"
date: "2025-11-03"
author: "Tai Vu"
excerpt: "Post training in large language models."
tags: ["LLM", "AI"]
readTime: "8 min read"
featured: true
slug: "llm-post-training"
---

# ðŸ§  Post-Training in Large Language Models: From Raw Intelligence to Practical Use

When we hear about models like ChatGPT, Claude, Gemini, Grok, etc. It's easy to think they were simply "trained once" on huge datasets and then magically became conversational assistants. In reality, what makes these models helpful, potile, and safe to interact with isn't only **pre-training** it's the stages that come after it: **mid-training**, **post-training**. In this series of posts, we'll only go into detail on post-training.

---

## I. Introduction
Think about this for a moment: GPT-3 was released in 2020. ChatGPT launched in late 2022. Same core model, but wildly different user experiences. What made the difference?

![base-model vs post-trained model](/posts/images/gpt3-vs-chatgpt.png)

### A Quick Experiment
Imagine you ask a language model: "How do I fix my car?"
**Before post-training,** it might respond: "How to fix a bike?"
**After post-training:** "I'd be happy to help! Could you tell me what specific issue you're experiencing?"
What changed? The model went through post-trainingâ€”a set of techniques that transformed raw intelligence into practical assistance.

### The Core Challenge
Pre-trained language models are like incredibly well-read people who've never learned to have a conversation. They've absorbed massive amounts of information from the internet by learning to predict the next word in billions of text examples. This gives them knowledge about almost everythingâ€”but no understanding of how to actually help you.

Ask them to write code, and they might describe what code should do rather than writing it. Ask a question, and they might generate another question. They have intelligence without direction.

![pretrained-model](/posts/images/pretrained-model.png)


### Post-Training: Teaching Models to Be Useful
This is where fine-tuning and reinforcement learning come inâ€”the two core techniques of post-training. Together, they teach models to:
- Have natural conversations and remember context.
- Follow instructions accurately.
- Refuse harmful requests while staying helpful.
- Use external tools when needed.
- Think step-by-step through complex problems.
- Adapt their style to different situations.

Every modern AI assistant you interact withâ€”ChatGPT, Claude, Geminiâ€”relies on these post-training techniques. It's what got us from research curiosity to practical tool.

![post-trained-model](/posts/images/post-trained-model.png)

### What's Ahead
In this post, you'll discover:

- How fine-tuning and reinforcement learning actually work (we'll use some helpful analogies).
- Why frontier labs use both techniques, not just one.
- Real examples: teaching models to reason and stay safe.
- How you might apply these techniques yourself.

Let's start by seeing where post-training fits in the complete journey of training a language model.